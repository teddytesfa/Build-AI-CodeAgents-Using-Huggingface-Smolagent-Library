# Build AI CodeAgents Using Huggingface smolagents Python Library
Build an Catering Service AI agent assistant using the smolagent HuggingFace Library.

- The code_agents_smolagent.ipynb notebook shows how to build agents that generate code to interact with external sources. It uses the Gemini LLM model as to think/reason & suggest appropriate plan. The agent is also deployed in the HuggingFace space. You can interact and expermint with the deployed agent in action here: https://huggingface.co/spaces/teddy-tesfa/AlfredAgent. 
  
- The building_AI_agents_that_utilize_tools.ipynb notebook shows how we can build AI agents that utilize tools to interact with external systems using the smolagents Tool creation methods. Here, the Qwen/Qwen3-Coder-30B-A3B-Instruct LLM model is used via Nebius Inference provider through the HuggingFace InferenceClientModel. The Catering Service Tool (implemented in the notebook) is also deployed in the HuggingFace space (https://huggingface.co/spaces/teddy-tesfa/catering_service_tool). Go and expermint with the catering Service Tool live in action in the HuggingFace space.
